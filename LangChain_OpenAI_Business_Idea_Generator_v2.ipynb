{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317a4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret_key import openapi_key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = openapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7cc4203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211517ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailv\\AppData\\Local\\Temp\\ipykernel_29780\\1188039162.py:8: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI()\n"
     ]
    }
   ],
   "source": [
    "# llm = OpenAI(temperature = .1,\n",
    "#             max_tokens=150,\n",
    "#     top_p=0.85,\n",
    "#     frequency_penalty=0.4,\n",
    "#     presence_penalty=0.3)\n",
    "\n",
    "\n",
    "llm = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68618d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailv\\AppData\\Local\\Temp\\ipykernel_29780\\11434669.py:1: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  name = llm(\"I want to open a restaurant for mexican food. Suggest a royal name for this.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"El Rey Mexicano\" (The Mexican King) \n"
     ]
    }
   ],
   "source": [
    "name = llm(\"I want to open a restaurant for mexican food. Suggest a royal name for this.\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a780b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d3c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step. Finish the answer in 25 words\"\"\"\n",
    "\n",
    "prompt_template_name1 = PromptTemplate(template=template, input_variables=[\"answer the question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3db257e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailv\\AppData\\Local\\Temp\\ipykernel_29780\\2233705290.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain2 = LLMChain(prompt=prompt_template_name1, llm=llm)\n"
     ]
    }
   ],
   "source": [
    "llm_chain2 = LLMChain(prompt=prompt_template_name1, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7fb9209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailv\\AppData\\Local\\Temp\\ipykernel_29780\\1844615220.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm_chain2.run(question)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nArtificial intelligence has its roots in ancient Greek myths and philosophical debates. The term \"artificial intelligence\" was coined in 1956 and has since seen significant advancements and controversies, shaping our modern world.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3\n",
    "question = \"Provide a brief overview of the history of artificial intelligence.\"\n",
    "\n",
    "llm_chain2.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd5a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06c89f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 1\n",
    "prompt_template_name=PromptTemplate(input_variables=[\"cuisine\"],\n",
    "                                    template=\"i want to open a restaurant for this {cuisine}, suggest a fancy name for it\")\n",
    "\n",
    "name_chain=LLMChain(llm=llm, prompt=prompt_template_name,output_key=\"restaurant_name\")\n",
    " \n",
    "# Prompt 2\n",
    "prompt_templates_items=PromptTemplate(input_variables=[\"restaurant_name\"],\n",
    "                                      template=\"suggest 3 fancy and unique menu items for this {restaurant_name}\")\n",
    "food_items_chain=LLMChain(llm=llm,prompt=prompt_templates_items, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daec4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=SequentialChain(\n",
    "    chains=[name_chain, food_items_chain], input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"restaurant_name\", \"menu_items\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f43539e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailv\\AppData\\Local\\Temp\\ipykernel_29780\\4196364530.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain({\"cuisine\": \"mexican\"})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'mexican',\n",
       " 'restaurant_name': '\\n\\n\"Casa de Sabores\" (House of Flavors)',\n",
       " 'menu_items': '\\n\\n1. \"Flamingo Fiesta Tacos\" - Grilled marinated flamingo meat served on a bed of colorful roasted peppers and topped with a spicy mango salsa.\\n\\n2. \"Octopus Ink Risotto\" - Creamy risotto infused with rich and savory octopus ink, topped with seared octopus tentacles and drizzled with a garlic herb butter sauce.\\n\\n3. \"Dragon\\'s Breath Ramen\" - Spicy broth filled with tender chunks of dragon meat, ramen noodles, and an assortment of exotic vegetables and spices. Served with a side of dragon breath hot sauce for those brave enough to try.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"cuisine\": \"mexican\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43d7c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Template\n",
    "prompt_template_name = PromptTemplate(input_variables=[\"industry\"],\n",
    "                                    template = \"I want to start a startup for {industry} , suggest me a good name for this\")\n",
    "\n",
    "name_chain = LLMChain(llm = llm, prompt = prompt_template_name)\n",
    "\n",
    "# Second Template\n",
    "prompt_template_items = PromptTemplate( input_variables = [\"name\"],\n",
    "                                     template = \"suggest 3 business strategies in bullet points for {name}\")\n",
    "\n",
    "strategies_chain = LLMChain(llm = llm, prompt = prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8eb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cbf9eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SimpleSequentialChain(chains=[name_chain, strategies_chain]) # This gives us one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cfc1bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"logistics\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b61682f",
   "metadata": {},
   "source": [
    "## Define a Function to Get Completion__\n",
    "The __get_completion__ function is responsible for sending a prompt to the OpenAI model and receiving its response.\n",
    "\n",
    "__Parameters:__\n",
    "\n",
    "- __prompt__: It is the text input for which the model will generate a completion.\n",
    "- __model__: The gpt-3.5-turbo model is used to perform the tasks.\n",
    "\n",
    "The __openai.ChatCompletion.create__ function is used to send a request to the OpenAI API.\n",
    "\n",
    "This request includes the model, the input messages (formatted as a list of dictionaries with user roles and content), and a temperature setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5bc61d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    # Create the messages list with the user prompt\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    # Create a chat completion request\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.1,\n",
    "        top_p=0.8\n",
    "\n",
    "    )\n",
    "    \n",
    "    # Return the content of the first response\n",
    "    return response.choices[0].message.content\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "834bd50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac6aea",
   "metadata": {},
   "source": [
    "# Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fcb1534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Salut, bonjour !\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English sentence to French:\n",
    "\n",
    "'Hey, Good Morning!'\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58675d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Salut, bonjour !\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English sentence to French:\n",
    "\n",
    "'Hey, Good Morning!'\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c63545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon Musk born in South Africa, moved to Canada, studied in the US, founded successful companies including SpaceX with PayPal money.\n"
     ]
    }
   ],
   "source": [
    "# Text Summarization\n",
    "\n",
    "prompt = \"\"\"\n",
    "Summarize the following text in 20 words:\n",
    "\n",
    "'Musk was born in Pretoria to model Maye and businessman and engineer Errol Musk, and briefly attended the University of Pretoria before immigrating to Canada at age 18, acquiring citizenship through his Canadian-born mother. Two years later, he matriculated at Queen's University at Kingston in Canada. Musk later transferred to the University of Pennsylvania and received bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University, but dropped out after two days and, with his brother Kimbal, co-founded online city guide software company Zip2. The startup was acquired by Compaq for $307 million in 1999. That same year, Musk co-founded X.com, a direct bank. X.com merged with Confinity in 2000 to form PayPal. In October 2002, eBay acquired PayPal for $1.5 billion. Using $100 million of the money he made from the sale of PayPal, Musk founded SpaceX, a spaceflight services company, in 2002.'\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fca82f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Italy is Rome.\n"
     ]
    }
   ],
   "source": [
    "# Question Answering\n",
    "\n",
    "prompt = \"\"\"\n",
    "Q: What is the capital of Italy?\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47550038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative feedback\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Feedback: \"Your customer support was helpful, Not very satisfied.\"\n",
    "Classification:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e0a45",
   "metadata": {},
   "source": [
    "# One Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "407127b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Q: What is the capital of Italy?\n",
    "A: \"Imperium Romanum in aeternum stabit.\", Rome\n",
    "\n",
    "Q: What is the capital of India?\n",
    "A:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf8e9a6",
   "metadata": {},
   "source": [
    "# Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f02e4a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"भारतीय साम्राज्य सदैव बना रहना चाहिए।\", New Delhi\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Q: What is the capital of Italy?\n",
    "A: \"Imperium Romanum in aeternum stabit.\", Rome\n",
    "\n",
    "Q: What is the capital of France?\n",
    "A: \"L'Empire romain devrait tenir pour l'éternité.\", Paris\n",
    "\n",
    "Q: What is the capital of Japan?\n",
    "A: \"日本は永遠に生き続けるべきです。\", Tokyo\n",
    "\n",
    "Q: What is the capital of Germany?\n",
    "A: \"Das Deutsche Reich sollte für immer bestehen.\", Berlin\n",
    "\n",
    "Q: What is the capital of Brazil?\n",
    "A: \"O Império Brasileiro deve durar para sempre.\", Brasília\n",
    "\n",
    "Q: What is the capital of India?\n",
    "A:\n",
    "\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e53cc4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems like a mixed sentiment, leaning towards Negative. We will work on improving our customer support to better satisfy you in the future.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Feedback: \"I loved the quick service and friendly staff.\"\n",
    "Classification: Great we are delighed to have a Positive sentiment\n",
    "\n",
    "Feedback: \"The product did not meet my expectations.\"\n",
    "Classification: Oops, we are afraid its a Negative sentiment\n",
    "\n",
    "Feedback: \"I am not sure if this is the right product for me.\"\n",
    "Classification: We will try to improve and satisfy you next time as its a Neutral sentiment\n",
    "\n",
    "Feedback: \"Your customer support was helpful, Not very satisfied.\"\n",
    "Classification:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ffd67fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Renew Your Subscription Now!\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Task: Generate a subject line for the following emails.\n",
    "\n",
    "Email: \"Thank you for your purchase! Your order has been shipped and will arrive in 3-5 business days.\"\n",
    "Subject: \"Your Order Has Shipped!\"\n",
    "\n",
    "Email: \"We noticed you left items in your cart. Don’t miss out on these great deals!\"\n",
    "Subject: \"Don’t Forget: Items Waiting in Your Cart!\"\n",
    "\n",
    "Email: \"We’ve just launched a new product line. Check out our latest arrivals and get 10% off your first purchase.\"\n",
    "Subject: \"Explore Our New Arrivals & Enjoy 10% Off!\"\n",
    "\n",
    "Email: \"Your subscription is about to expire. Renew now to continue enjoying our services.\"\n",
    "Subject:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f87662d",
   "metadata": {},
   "source": [
    "# Chain Of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "261d631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the condition that it is raining, the solution is to carry an umbrella. This will help protect you from getting wet in the rain. Thank you for following the steps and logic provided.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "let's break down the problem step by step\n",
    "\n",
    "1. Chek the condition: is it raining?\n",
    "2. if yes, then aswers should be something like Carry an umbrella\n",
    "3. If it is not raining, the answer hould be something like Do not carry umbrella, but be careful\n",
    "4. provide the final solution to the user exxplining the logic.\n",
    "\n",
    "\n",
    "it is raining.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c9281cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: [3,1,4,6,5,9,2]\n",
      "Step 2: [1,3,4,6,5,9,2]\n",
      "Step 3: [1,2,4,6,5,9,3]\n",
      "Step 4: [1,2,3,6,5,9,4]\n",
      "Step 5: [1,2,3,4,5,9,6]\n",
      "Step 6: [1,2,3,4,5,6,9]\n",
      "\n",
      "Sorted list: [1,2,3,4,5,6,9]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "let's sort the values of the list step by step\n",
    "\n",
    "1. Start with the unsorted list.\n",
    "2. Compare each elements and find the smallest value.\n",
    "3. Place the samllest value in the first position.\n",
    "4. Repeat the process for all the remaming elements.\n",
    "5. provide the sorted list.\n",
    "\n",
    "Sort the list : [3,1,4,6,5,9,2]\n",
    "\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64aa6fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Positive aspect: \"The product is well designed\" - Score: 8/10\n",
      "2. Negative aspect: \"less functional\" - Score: 6/10\n",
      "3. Weighting: Positive aspect (8) x 0.6 (weight) = 4.8, Negative aspect (6) x 0.4 (weight) = 2.4\n",
      "4. Final sentiment classification: Overall sentiment is slightly positive. The positive aspect of the well-designed product outweighs the negative aspect of being less functional. The final sentiment score would be 4.8 out of 10, leaning towards a positive sentiment.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "let's analyze the sentiment of the review step by step\n",
    "\n",
    "1. Identify the Positive aspect of the review and give a score from 10 \n",
    "2. Identify the Negative aspect of the review and give a score from 10\n",
    "3. weight the positive and negative aspect to determine the overall sentiment.\n",
    "4. provide the final sentiment classification with justification for scores used in above steps\n",
    "\n",
    "Review: \"The product is well designed but less functional\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35341e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Sort the values of the list \n",
    "\n",
    "Sort the list : [3,1,4,6,5,9,2]\n",
    "\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b7cc9",
   "metadata": {},
   "source": [
    "# Sequential or Conversational Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78721b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Imagine you are a detective trying to solve a mystery.\n",
      "Response: As a detective, I am faced with a perplexing mystery that has left the community in fear and confusion. The case involves a series of seemingly random disappearances of young women in the town. The only clue left behind is a cryptic note found at each crime scene, written in a language that no one can decipher.\n",
      "\n",
      "I begin my investigation by interviewing the families and friends of the missing women, trying to piece together their last known whereabouts and any potential connections between them. I also analyze the notes left behind, hoping to find a pattern or clue that could lead me to the perpetrator.\n",
      "\n",
      "As I delve deeper into the case, I uncover a web of deceit and betrayal among the townspeople, with secrets and lies lurking beneath the surface. I follow leads and track down suspects, but each one seems to lead me further away from the truth.\n",
      "\n",
      "Finally, after weeks of tireless investigation, I stumble upon a breakthrough. A witness comes forward with crucial information that points me towards a suspect who had been overlooked in the initial stages of the investigation. With this new lead, I am able to piece together the puzzle and track down the perpetrator.\n",
      "\n",
      "In a dramatic showdown, I confront the culprit and bring them to justice, bringing closure to the families of the missing women and restoring peace to the town. As I reflect on the case, I am reminded of the importance of perseverance and dedication in solving even the most challenging mysteries.\n",
      "\n",
      "Prompt: You arrive at the crime scene and start looking for clues.\n",
      "Response: You notice a broken window with shards of glass scattered on the ground. There are also muddy footprints leading away from the window towards the back of the house. As you follow the footprints, you see a crowbar lying on the ground, which may have been used to break the window. \n",
      "\n",
      "You also find a torn piece of fabric caught on a nearby bush, which could be from the suspect's clothing. Additionally, you spot a discarded glove with a distinct logo on it, possibly belonging to the perpetrator.\n",
      "\n",
      "As you continue to search the area, you come across a discarded wallet with identification inside. This could potentially lead you to the suspect's identity.\n",
      "\n",
      "You take note of all the evidence and carefully collect and bag each item for further analysis. It's clear that the perpetrator left behind several clues that could help lead to their capture.\n",
      "\n",
      "Prompt: You find a strange object at the crime scene. What is it?\n",
      "Response: It appears to be a small, metallic device with intricate engravings on its surface. It emits a faint humming sound and glows softly in the dark. Its purpose and origin are unknown, adding to the mystery of the crime scene.\n",
      "\n",
      "Prompt: How does this object relate to the crime?\n",
      "Response: Without knowing what the object is or any context about the crime, it is impossible to determine how the object may relate to the crime. More information would be needed to make that connection.\n",
      "\n",
      "Prompt: Who do you think is the suspect and why?\n",
      "Response: Without more information about the situation or context, it is impossible to determine who the suspect may be. It is important to gather evidence and information before making any accusations or assumptions about someone's guilt.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Imagine you are a detective trying to solve a mystery.\",\n",
    "    \"You arrive at the crime scene and start looking for clues.\",\n",
    "    \"You find a strange object at the crime scene. What is it?\",\n",
    "    \"How does this object relate to the crime?\",\n",
    "    \"Who do you think is the suspect and why?\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = get_completion(prompt)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e034b3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Describe the issue you are experiencing with your device.\n",
      "Response: I am experiencing slow performance and frequent freezing on my device. It takes a long time to open apps and switch between them, and sometimes the device becomes unresponsive and I have to restart it.\n",
      "\n",
      "Prompt: Have you tried restarting your device? If not, please do so and describe what happens.\n",
      "Response: I'm sorry, I am an AI and do not have the capability to restart a device. However, if you are experiencing issues with your device, I recommend restarting it to see if that resolves the problem. If you can provide more details about the issue you are facing, I may be able to offer further assistance.\n",
      "\n",
      "Prompt: What is the model number of your device?\n",
      "Response: I'm sorry, I am a virtual assistant and do not have a physical device. I am here to assist you with any questions or information you may need.\n",
      "\n",
      "Prompt: Based on the model number, these are common issues. Which one matches your problem?\n",
      "Response: I'm sorry, but you did not provide a model number or list any common issues. Please provide more information so I can assist you further.\n",
      "\n",
      "Prompt: Here are the steps to resolve this issue. Follow them one by one, and let me know if the problem persists.\n",
      "Response: 1. Restart your device: Sometimes a simple restart can resolve many issues. Turn off your device, wait a few seconds, and then turn it back on.\n",
      "\n",
      "2. Check for software updates: Make sure your device's operating system and any relevant apps are up to date. Updates often include bug fixes that can resolve issues.\n",
      "\n",
      "3. Clear cache and cookies: Clearing your browser's cache and cookies can help resolve website loading issues. Go to your browser's settings and clear the cache and cookies.\n",
      "\n",
      "4. Check your internet connection: Make sure you have a stable internet connection. Try connecting to a different network or restarting your router.\n",
      "\n",
      "5. Disable browser extensions: Sometimes browser extensions can cause issues with website loading. Disable any extensions you have installed and see if that resolves the problem.\n",
      "\n",
      "6. Try a different browser: If the issue persists, try accessing the website using a different browser to see if the problem is specific to one browser.\n",
      "\n",
      "7. Contact the website's support: If you are still experiencing issues, reach out to the website's support team for further assistance. Provide them with details about the problem you are facing.\n",
      "\n",
      "8. Consider using a VPN: If the website is geo-blocked or restricted in your location, consider using a VPN to access it. This can help bypass any restrictions that may be causing the issue.\n",
      "\n",
      "If you have followed these steps and are still experiencing issues, please provide me with more details so I can further assist you in resolving the problem.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Describe the issue you are experiencing with your device.\",\n",
    "    \"Have you tried restarting your device? If not, please do so and describe what happens.\",\n",
    "    \"What is the model number of your device?\",\n",
    "    \"Based on the model number, these are common issues. Which one matches your problem?\",\n",
    "    \"Here are the steps to resolve this issue. Follow them one by one, and let me know if the problem persists.\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = get_completion(prompt)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7339457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Please describe the main symptoms you are experiencing.\n",
      "Response: I'm sorry, but as an AI, I do not have any physical sensations or symptoms. I am here to assist you with any questions or concerns you may have. If you are experiencing symptoms, it is important to consult with a healthcare professional for an accurate diagnosis and appropriate treatment.\n",
      "\n",
      "Prompt: How long have you been experiencing these symptoms?\n",
      "Response: I'm sorry, but I am not experiencing any symptoms as I am an AI assistant. How can I assist you today?\n",
      "\n",
      "Prompt: Do you have any pre-existing conditions or allergies?\n",
      "Response: I'm sorry, I am an AI assistant and do not have any pre-existing conditions or allergies.\n",
      "\n",
      "Prompt: Have you traveled recently or come into contact with anyone who is sick?\n",
      "Response: I am an AI and do not have the ability to travel or come into contact with others.\n",
      "\n",
      "Prompt: Based on your symptoms and history, these are potential diagnoses. Which one seems most accurate to you?\n",
      "Response: I'm sorry, but I am not able to provide medical diagnoses as I am just a language model AI. It is important to consult with a healthcare professional for an accurate diagnosis and treatment plan.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Please describe the main symptoms you are experiencing.\",\n",
    "    \"How long have you been experiencing these symptoms?\",\n",
    "    \"Do you have any pre-existing conditions or allergies?\",\n",
    "    \"Have you traveled recently or come into contact with anyone who is sick?\",\n",
    "    \"Based on your symptoms and history, these are potential diagnoses. Which one seems most accurate to you?\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = get_completion(prompt)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46feac",
   "metadata": {},
   "source": [
    "# Self-Consistency Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "599e2c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 30-pound weight is heavier than 1000 feathers.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Let's consider which is heavier: 1000 feathers or a 30-pound weight. I'll think through this in a few different ways and then decide which answer seems most consistent.\n",
    "\n",
    "1. First line of reasoning: A single feather is very light, almost weightless. So, 1000 feathers might still be quite light, possibly lighter than a 30-pound weight.\n",
    "\n",
    "2. Second line of reasoning: 1000 is a large number, and when you add up the weight of so many feathers, it could be quite heavy. Maybe it's heavier than a 30-pound weight.\n",
    "\n",
    "3. Third line of reasoning: The average weight of a feather is very small. Even 1000 feathers would not add up to 30 pounds.\n",
    "\n",
    "Considering these reasonings, the most consistent answer is:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6145323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First approach:\n",
      "15 - 3 = 12\n",
      "12 + 8 = 20\n",
      "20 - 5 = 15\n",
      "\n",
      "Second approach:\n",
      "8 - 5 = 3\n",
      "15 - 3 = 12\n",
      "\n",
      "Third approach:\n",
      "Starting with 15 apples:\n",
      "15 - 3 = 12\n",
      "12 + 8 = 20\n",
      "20 - 5 = 15\n",
      "\n",
      "It looks like all three approaches lead to the same answer of 15 apples. So, the final answer is 15 apples.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "I will solve the following math problem in several different ways and check if I arrive at the same answer each time.\n",
    "\n",
    "Problem: If you have 15 apples and you give away 3, then gain 8 more, and finally lose 5, how many apples do you have?\n",
    "\n",
    "1. First approach: Start by subtracting 3 from 15, then add 8, and subtract 5.\n",
    "\n",
    "2. Second approach: Combine the gains and losses first (8 - 5), then apply the net change to the original number of apples (15 - 3 + net change).\n",
    "\n",
    "3. Third approach: Apply each operation in sequence and keep track of the apples after each step.\n",
    "\n",
    "Let's see which approach gives the most consistent result.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7af76",
   "metadata": {},
   "source": [
    "# Tree-Of-Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73fd92e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "The dimensions should be 40 meters by 20 meters, creating a rectangular field with an area of 800 square meters.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Solve the problem: A farmer has 100 meters of fencing and wants to enclose the maximum area for his rectangular field. What should the dimensions be?\n",
    "\n",
    "Let's think about this in a few ways:\n",
    "\n",
    "1. If the field is a square, each side would be 100 / 4 = 25 meters. The area would be 25 * 25 = 625 square meters.\n",
    "\n",
    "2. What if the field is not a square? Let's try a 2:1 ratio. The lengths would be 40 and 20 meters. The area would be 40 * 20 = 800 square meters.\n",
    "\n",
    "3. Are there any other ratios that might give a larger area than a square or a 2:1 rectangle?\n",
    "\n",
    "Considering these options, the best dimensions for the maximum area are:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4e39fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Fourth branch: Start by visiting city D first, then C, then B, and finally A. Compare this route with the previous ones to determine if it offers any time or distance savings.\n",
      "\n",
      "5. Fifth branch: Start by visiting city A first, then C, then B, and finally D. Evaluate if this route provides any advantages over the other options.\n",
      "\n",
      "By thoroughly analyzing each branch and comparing the total distance and time required for each route, I will be able to determine the most efficient path to visit cities A, B, C, and D. This systematic approach will help me make an informed decision and optimize my travel itinerary.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "I need to plan the most efficient route to visit the following cities: A, B, C, and D. I'll explore different routes and their implications, step by step, to find the best option.\n",
    "\n",
    "1. First branch: Start by visiting city A, then move to city B, then to city C, and finally to city D. Consider the total distance and time required.\n",
    "\n",
    "2. Second branch: Start by visiting city B first, then A, then D, and finally C. Evaluate if this route is shorter or faster than the first.\n",
    "\n",
    "3. Third branch: Start by visiting city C first, then D, then A, and finally B. Analyze if this route offers any advantages over the others.\n",
    "\n",
    "At each step, I'll compare the results of each branch and see which provides the most efficient route. If needed, I will explore sub-branches by adjusting the sequence slightly.\n",
    "\n",
    "Let's see which path is the most optimal.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a352c4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering that August is monsoon season in Goa, it is likely that the weather will be cloudy or rainy. Therefore, it might be best to choose Option 2 and go to the beach. In this case, Branch D would be the most suitable choice, where you can visit indoor attractions like an aquarium or go shopping in beachside stores. This way, you can still enjoy your weekend trip to Goa despite the weather conditions.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Let's plan a weekend trip by considering multiple options.\n",
    "\n",
    "1. Option 1: Go to the mountains.\n",
    "    - Branch A: If the weather is good in the mountains.\n",
    "        - Sub-branch A1: You can go hiking.\n",
    "        - Sub-branch A2: You can visit a nearby lake.\n",
    "    - Branch B: If the weather is bad in the mountains.\n",
    "        - Sub-branch B1: You will stay in a cabin and relax.\n",
    "        - Sub-branch B2: You can explore local museums.\n",
    "\n",
    "2. Option 2: Go to the beach.\n",
    "    - Branch C: If the weather is sunny at the beach.\n",
    "        - Sub-branch C1: You can swim in the ocean.\n",
    "        - Sub-branch C2: You can sunbathe and play beach volleyball.\n",
    "    - Branch D: If the weather is cloudy or rainy at the beach.\n",
    "        - Sub-branch D1: You will visit indoor attractions like an aquarium.\n",
    "        - Sub-branch D2: You can go shopping in beachside stores.\n",
    "\n",
    "3. Considering all these factors, decide the best option for your weekend trip.\n",
    "\n",
    "What should i do for my trip to Goa in month of august\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec5a772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the facts of the current case, it seems that there is clear evidence of negligence on the part of the defendant. The plaintiff suffered harm due to the defendant's actions, and there is a breach of duty that can be proven. Therefore, based on Precedent 1, it is likely that the court will rule in favor of the plaintiff and award damages for the harm suffered. The defendant may be found negligent and held responsible for compensating the plaintiff for their losses.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"\"\"\n",
    "Let's analyze the legal case by considering multiple precedents and possible outcomes.\n",
    "\n",
    "1. Precedent 1: A similar case where the plaintiff won.\n",
    "    - Branch A: The court found that the defendant was negligent.\n",
    "        - Sub-branch A1: The plaintiff was awarded damages due to clear evidence of negligence.\n",
    "        - Sub-branch A2: The court ruled in favor of the plaintiff due to the defendant's breach of duty.\n",
    "\n",
    "2. Precedent 2: A similar case where the defendant won.\n",
    "    - Branch B: The court found no negligence on the defendant's part.\n",
    "        - Sub-branch B1: The plaintiff failed to provide sufficient evidence.\n",
    "        - Sub-branch B2: The court ruled that the plaintiff assumed the risk.\n",
    "\n",
    "3. Precedent 3: A case with a mixed outcome.\n",
    "    - Branch C: The court found both parties partially at fault.\n",
    "        - Sub-branch C1: Damages were reduced based on the plaintiff's contributory negligence.\n",
    "        - Sub-branch C2: The court ruled that both parties shared liability, resulting in a split decision.\n",
    "\n",
    "4. Based on the facts of the current case, consider the most likely outcome.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a06fe6",
   "metadata": {},
   "source": [
    "# Using Jinja2 Template Format__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb11b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables - to incluse any valiable we will need {{Var-Name}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07d333b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e586ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jinja2_template = \"Give me an {{ adjective }} fact about {{ topic }}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55997278",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a97f216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me an interesting fact about space exploration\n"
     ]
    }
   ],
   "source": [
    "question = prompt.format(adjective=\"interesting\", topic=\"space exploration\")\n",
    "\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5171bd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "The farthest spacecraft from Earth is Voyager 1, which was launched in 1977 and is currently over 14 billion miles away from Earth. It is the only human-made object to have entered interstellar space, beyond our solar system.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(question)\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79197727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "Investing in renewable energy is crucial for governments in the next decade for several reasons. \n",
      "\n",
      "First and foremost, renewable energy sources such as solar, wind, and hydro power are sustainable and environmentally friendly alternatives to fossil fuels. As the effects of climate change become increasingly severe, it is imperative that governments take action to reduce greenhouse gas emissions and transition to cleaner energy sources. Investing in renewable energy will help to mitigate the impacts of climate change and protect the planet for future generations.\n",
      "\n",
      "Additionally, investing in renewable energy can create jobs and stimulate economic growth. The renewable energy sector is one of the fastest growing industries in the world, and governments that prioritize renewable energy development can attract investment, create new jobs, and boost local economies. By investing in renewable energy, governments can also reduce their dependence on imported fossil fuels and improve energy security.\n",
      "\n",
      "Furthermore, investing in renewable energy can help to reduce energy costs for consumers. Renewable energy sources are becoming increasingly cost-competitive with traditional fossil fuels, and as technology continues to improve, the cost of renewable energy is expected to continue to decline. By investing in renewable energy infrastructure, governments can help to lower energy costs for consumers and businesses, making energy more affordable and accessible for all.\n",
      "\n",
      "In conclusion, investing in renewable energy is not only important for addressing climate change and protecting the environment, but it also has the potential to create jobs, stimulate economic growth, and reduce energy costs. Governments that prioritize renewable energy development in the next decade will be better positioned to meet the challenges of the future and build a more sustainable and prosperous society for all.\n"
     ]
    }
   ],
   "source": [
    "jinja2_template = \"Make a convincing argument for why {{ action }} is important for {{ group }} in {{ time_period }}.\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
    "\n",
    "# Format the prompt with specific values for 'action', 'group', and 'time_period'\n",
    "argument_prompt = prompt.format(action=\"investing in renewable energy\", group=\"governments\", time_period=\"the next decade\")\n",
    "\n",
    "response = get_completion(argument_prompt)\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06972c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "Investing in renewable energy is crucial for governments in the next decade to combat climate change, reduce dependence on fossil fuels, create jobs, and stimulate economic growth. It is essential for a sustainable future, ensuring energy security and protecting the environment for future generations.\n"
     ]
    }
   ],
   "source": [
    "jinja2_template = \"In 50 words or less, Make a convincing argument for why {{ action }} is important for {{ group }} in {{ time_period }}.\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
    "\n",
    "# Format the prompt with specific values for 'action', 'group', and 'time_period'\n",
    "argument_prompt = prompt.format(action=\"investing in renewable energy\", group=\"governments\", time_period=\"the next decade\")\n",
    "\n",
    "response = get_completion(argument_prompt)\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9bc935",
   "metadata": {},
   "source": [
    "# String Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "daf40875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bd08b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \" Please write a {length} review,of the book {book_title}. Focus on being very precise. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d781a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variables = {\n",
    "    \n",
    "    \"length\" : \"Short\",\n",
    "    \"book_title\" : \"House of dragon\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c05896db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the prompt template\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=input_variables,\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bfb46fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the prompt by filling in the placeholders with specific values\n",
    "\n",
    "# formatted_prompt = prompt.format(**input_variables)\n",
    "\n",
    "formatted_prompt = prompt.format(length = \"Short\", book_title = \"House of dragon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a89c56b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Please write a Short review,of the book House of dragon. Focus on being very precise. '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05b0aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "House of Dragon is a captivating fantasy novel that follows the story of a powerful dragon family and their quest for power and control. The intricate plot and well-developed characters make for an engaging read that will keep readers on the edge of their seats. The vivid descriptions and detailed world-building bring the story to life, making it a must-read for fans of the genre. Overall, House of Dragon is a thrilling and immersive read that will leave readers eagerly anticipating the next installment.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(formatted_prompt)\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "073dc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv, yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e0a3be1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'file_name.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      2\u001b[0m     input_Variable \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_Variable)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'file_name.json'"
     ]
    }
   ],
   "source": [
    "with open(\"file_name.json\",\"r\") as file:\n",
    "    input_Variable = json.load(file)\n",
    "    \n",
    "print(input_Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09382b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a short story about a brave knight who discovers a magic sword in enchanted forest.\n"
     ]
    }
   ],
   "source": [
    "# Define a simple string template with placeholders\n",
    "template_str = \"Write a short story about a {character} who discovers a {object} in {location}.\"\n",
    "\n",
    "# Create a PromptTemplate object with the template string and a list of input variables\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"character\", \"object\", \"location\"],\n",
    "    template=template_str\n",
    ")\n",
    "\n",
    "# Format the prompt by filling in the placeholders with specific values\n",
    "formatted_prompt = prompt.format(character=\"brave knight\", object=\"magic sword\", location=\"enchanted forest\")\n",
    "\n",
    "# Print the formatted prompt\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aedcb669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "Sir William was known throughout the kingdom as the bravest knight in all the land. He had faced countless foes and emerged victorious every time. But one day, while on a quest to rid the kingdom of a fearsome dragon, Sir William found himself lost in an enchanted forest.\n",
      "\n",
      "As he wandered through the dense trees, Sir William heard whispers in the wind and felt a strange energy in the air. Suddenly, he stumbled upon a clearing where a magnificent sword lay embedded in a stone. The blade shimmered with an otherworldly light, and Sir William knew that this was no ordinary weapon.\n",
      "\n",
      "With a determined look in his eye, Sir William grasped the hilt of the sword and pulled with all his might. To his surprise, the sword came free effortlessly, as if it had been waiting for him all along. As he held the sword aloft, a surge of power coursed through his veins, and he knew that this was no ordinary weapon.\n",
      "\n",
      "With his newfound sword in hand, Sir William continued his journey through the enchanted forest, feeling invincible and unstoppable. He soon came face to face with the dragon, its fiery breath scorching the earth around them. But Sir William did not falter. With a mighty swing of his magic sword, he struck the dragon down, vanquishing the beast once and for all.\n",
      "\n",
      "The kingdom rejoiced at the news of Sir William's victory, and he was hailed as a hero. But Sir William knew that it was not his skill or bravery alone that had won the day. It was the magic sword, a gift from the enchanted forest, that had guided his hand and granted him the strength to overcome any obstacle.\n",
      "\n",
      "And so, Sir William continued on his adventures, wielding his magic sword with pride and courage, knowing that he was destined for greatness thanks to the enchanted forest and the powerful weapon it had bestowed upon him.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(formatted_prompt)\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7511876e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write a short review of the book 'Dune' by Frank Herbert. Focus on the character development.\n"
     ]
    }
   ],
   "source": [
    "template = \"Please write a {length} review of the book '{book_title}' by {author}. Focus on the {aspect}.\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"length\", \"book_title\", \"author\", \"aspect\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    length=\"short\",\n",
    "    book_title=\"Dune\",\n",
    "    author=\"Frank Herbert\",\n",
    "    aspect=\"character development\"\n",
    ")\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8779b1",
   "metadata": {},
   "source": [
    "# String Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e869d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6681ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = Template(\"Hello, my name is $name and i am $age years old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b95af57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_template = template.substitute(name = \"Raghav\", age = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f586163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, my name is Raghav and i am 50 years old'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2113915",
   "metadata": {},
   "source": [
    "# String Format \"str.format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e2cbb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Hello, my name is {name} and i am {age} years old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d067a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_t = template.format(name = \"Raghav\", age = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9fbd42f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, my name is Raghav and i am 50 years old'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ee640",
   "metadata": {},
   "source": [
    "# Using 'f - String'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d90eceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Raghav\"\n",
    "age = 50\n",
    "\n",
    "f_mm = f'Hello, my name is {name} and i am {age} years old.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6cfbf90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, my name is Raghav and i am 50 years old.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40523a87",
   "metadata": {},
   "source": [
    "# Creating a Custom Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "775f0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import StringPromptTemplate\n",
    "from pydantic import BaseModel, validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57996d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\\\n",
    "Given the book title, generate a brief summary of the book.\n",
    "Book Title: {book_title}\n",
    "Summary:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b950307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=123 name='Alice' email='alice@example.com' age=25 friends=[234, 345, 456]\n",
      "[{\"type\":\"int_parsing\",\"loc\":[\"age\"],\"msg\":\"Input should be a valid integer, unable to parse string as an integer\",\"input\":\"twenty-five\",\"url\":\"https://errors.pydantic.dev/2.10/v/int_parsing\"}]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, ValidationError\n",
    "from typing import List\n",
    "\n",
    "# Define a Pydantic model\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    email: str\n",
    "    age: int\n",
    "    friends: List[int] = []\n",
    "\n",
    "# Valid data\n",
    "data = {\n",
    "    \"id\": 123,\n",
    "    \"name\": \"Alice\",\n",
    "    \"email\": \"alice@example.com\",\n",
    "    \"age\": 25,\n",
    "    \"friends\": [234, 345, 456]\n",
    "}\n",
    "\n",
    "# Instantiate the model with valid data\n",
    "user = User(**data)\n",
    "print(user)\n",
    "\n",
    "# Invalid data (age should be an integer)\n",
    "invalid_data = {\n",
    "    \"id\": 124,\n",
    "    \"name\": \"Bob\",\n",
    "    \"email\": \"bob@example.com\",\n",
    "    \"age\": \"twenty-five\",  # Invalid age\n",
    "    \"friends\": [234, 345]\n",
    "}\n",
    "\n",
    "try:\n",
    "    invalid_user = User(**invalid_data)\n",
    "except ValidationError as e:\n",
    "    print(e.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "abc3ec60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the book title, generate a brief summary of the book.\n",
      "Book Title: The Great Gatsby\n",
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, validator\n",
    "\n",
    "class StringPromptTemplate:\n",
    "    def __init__(self, template):\n",
    "        self.template = template\n",
    "\n",
    "    def format(self, **kwargs):\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "class BookSummarizerPrompt(BaseModel):\n",
    "    book_title: str\n",
    "    template: StringPromptTemplate\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def create_prompt(self):\n",
    "        return self.template.format(book_title=self.book_title)\n",
    "\n",
    "# Assuming an instance of StringPromptTemplate is created elsewhere\n",
    "template = StringPromptTemplate(\n",
    "    \"\"\"\\\n",
    "Given the book title, generate a brief summary of the book.\n",
    "Book Title: {book_title}\n",
    "Summary:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Usage\n",
    "book_summarizer_prompt = BookSummarizerPrompt(book_title=\"The Great Gatsby\", template=template)\n",
    "print(book_summarizer_prompt.create_prompt())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83fb64d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "\"The Great Gatsby\" follows the story of Jay Gatsby, a wealthy and mysterious man who throws extravagant parties in the hopes of rekindling a romance with his former love, Daisy Buchanan. Set in the 1920s, the novel explores themes of love, wealth, and the American Dream, as Gatsby's obsession with Daisy ultimately leads to tragedy. Through the eyes of narrator Nick Carraway, readers are taken on a journey through the glamorous and tumultuous world of the Jazz Age.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(book_summarizer_prompt.create_prompt())\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd9eae",
   "metadata": {},
   "source": [
    "# Few Shot Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8889b1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: 9, 13, 17, 21, 25, 29\n",
      "Sum: 114\n",
      "Answer: Even\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Task:\n",
    "You're provided with sequences of odd numbers. Your task is to determine if the sum of the numbers in each sequence results in an even number. If the sum is even, respond with \"Even.\" If the sum is odd, respond with \"Odd.\"\n",
    "\n",
    "Examples:\n",
    "\n",
    "Sequence: 3, 7, 15, 21, 8, 11, 4\n",
    "Sum: 57\n",
    "Answer: Odd\n",
    "\n",
    "Sequence: 5, 12, 19, 25, 10, 13, 3\n",
    "Sum: 65\n",
    "Answer: Odd\n",
    "\n",
    "Sequence: 6, 14, 21, 9, 11, 17, 7\n",
    "Sum: 65\n",
    "Answer: Odd\n",
    "\n",
    "Sequence: 8, 16, 24, 10, 13, 18, 5\n",
    "Sum: 26\n",
    "Answer: Even\n",
    "\n",
    "Sequence: 15, 32, 5, 13, 27, 7, 1\n",
    "Sum: 68\n",
    "Answer: Even\n",
    "\n",
    "New Sequence:\n",
    "Sequence: 9, 13, 17, 21, 25, 29\n",
    "Sum:\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e86382",
   "metadata": {},
   "source": [
    "# Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f816f128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the best way to learn a new language?\n",
      "The Learning is strong in this one.\n",
      "Summarize our conversation so far in 10 words.\n",
      "Best way to learn new language: practice, immersion, consistency, dedication.\n",
      "\n",
      "--- Updated Conversation ---\n",
      "\n",
      "What's the best way to learn a new language?\n",
      "The Learning is strong in this one.\n",
      "Summarize our conversation so far in 10 words.\n",
      "Best way to learn new language: practice, immersion, consistency, dedication.\n",
      "Can you give me some specific strategies?\n",
      "Practice speaking, listening, reading, writing daily. Immerse yourself in language. Consistency is key.\n",
      "\n",
      "--- Conversation with Summary ---\n",
      "\n",
      "What's the best way to learn a new language?\n",
      "The Learning is strong in this one.\n",
      "Summarize our conversation so far in 10 words.\n",
      "Best way to learn new language: practice, immersion, consistency, dedication.\n",
      "Can you give me some specific strategies?\n",
      "Practice speaking, listening, reading, writing daily. Immerse yourself in language. Consistency is key.\n",
      "Summarize our conversation so far in exactly 10 words.\n",
      "Practice speaking, listening, reading, writing daily. Consistency is key. Immersion.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    # Create the messages list with the user prompt\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    # Create a chat completion request\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.4,\n",
    "        top_p=0.8\n",
    "        # Degree of randomness in the model's output\n",
    "    )\n",
    "    \n",
    "    # Return the content of the first response\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Step 1: Import the Necessary Components\n",
    "from langchain.prompts import MessagesPlaceholder, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Step 2: Define Message Templates\n",
    "simple_prompt = \"The {subject} is strong in this one.\"\n",
    "human_prompt = \"Summarize our conversation so far in {word_count} words.\"\n",
    "\n",
    "# Step 3: Create a Chat Prompt with Placeholders\n",
    "simple_message_template = HumanMessagePromptTemplate.from_template(simple_prompt)\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "    simple_message_template,\n",
    "    human_message_template\n",
    "])\n",
    "\n",
    "# Step 4: Define the Initial Conversation Messages\n",
    "# Starting the conversation with a user input only, no predefined AI response\n",
    "initial_human_message = HumanMessage(content=\"What's the best way to learn a new language?\")\n",
    "\n",
    "# Step 5: Generate the Initial Conversation\n",
    "initial_conversation = chat_prompt.format_prompt(\n",
    "    conversation=[initial_human_message],\n",
    "    subject=\"Learning\",\n",
    "    word_count=\"10\"\n",
    ").to_messages()\n",
    "\n",
    "# Step 6: Format the Conversation for the LLM\n",
    "conversation_prompt = \"\\n\".join([message.content for message in initial_conversation])\n",
    "\n",
    "# Step 7: Use the OpenAI API to Generate the First AI Response\n",
    "llm_response = get_completion(conversation_prompt, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Step 8: Add the LLM's Response to the Conversation\n",
    "first_ai_message = AIMessage(content=llm_response)\n",
    "initial_conversation.append(first_ai_message)\n",
    "\n",
    "# Step 9: Print the Conversation\n",
    "for message in initial_conversation:\n",
    "    print(message.content)\n",
    "\n",
    "# Step 10: Continue the Conversation Dynamically\n",
    "# Example of continuing the conversation with a new user input\n",
    "# Assuming the same setup as before\n",
    "\n",
    "# Step 10: Continue the Conversation Dynamically\n",
    "# Example of continuing the conversation with a new user input\n",
    "new_human_message = HumanMessage(content=\"Can you give me some specific strategies?\")\n",
    "initial_conversation.append(new_human_message)\n",
    "\n",
    "# Update the prompt with the latest conversation\n",
    "conversation_prompt = \"\\n\".join([message.content for message in initial_conversation])\n",
    "\n",
    "# Get the next AI response\n",
    "new_llm_response = get_completion(conversation_prompt, model=\"gpt-3.5-turbo\")\n",
    "new_ai_message = AIMessage(content=new_llm_response)\n",
    "initial_conversation.append(new_ai_message)\n",
    "\n",
    "# Print the updated conversation\n",
    "print(\"\\n--- Updated Conversation ---\\n\")\n",
    "for message in initial_conversation:\n",
    "    print(message.content)\n",
    "\n",
    "# Requesting a 10-word summary as a separate, explicit instruction\n",
    "summary_request = \"Summarize our conversation so far in exactly 10 words.\"\n",
    "\n",
    "# Add the summary request to the conversation\n",
    "initial_conversation.append(HumanMessage(content=summary_request))\n",
    "\n",
    "# Update the prompt for summary\n",
    "summary_prompt = \"\\n\".join([message.content for message in initial_conversation])\n",
    "\n",
    "# Get the summary response\n",
    "summary_response = get_completion(summary_prompt, model=\"gpt-3.5-turbo\")\n",
    "summary_ai_message = AIMessage(content=summary_response)\n",
    "initial_conversation.append(summary_ai_message)\n",
    "\n",
    "# Print the conversation including the summary\n",
    "print(\"\\n--- Conversation with Summary ---\\n\")\n",
    "for message in initial_conversation:\n",
    "    print(message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5f4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
